---
title: "401_gender"
author: "Grace Lock"
date: "2024-03-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(haven) #Reading in the data
library(dplyr)
library(tidyverse)
library(socsci) #Helps with data manipulation
library(glmnet) #Lasso Regression
library(nnet) #Multinomial Logistic Regression
library(rpart) #Regression Tree
library(leaps) #Best subset regression
library(MASS) #Ordinal logistic regression
```


### Gender data 

```{r}
genderdata <- read_sav("/Users/gracelock/Downloads/Gender-Career IAT.public.2023.sav")
```

```{r}
genderdata |> dplyr::select("session_id", "birthyear", "num_002", "birthSex", "ethnicityomb", "edu",
                     "raceomb_002", "D_biep.Male_Career_all", "impcareer", "impfamily", "politicalid_7") |> 
              na.omit("D_biep.Male_Career_all") |>
              rename("num_tests" = "num_002",
                     "ethnicity" = "ethnicityomb",
                     "race" = "raceomb_002",
                     "politicalid" = "politicalid_7",
                     "score" = "D_biep.Male_Career_all",
                     "att_family" = "impfamily",
                     "att_carerr" = "impcareer") |>
              mutate(age = 2024 - birthyear) |> 
              dplyr::select(-birthyear) -> genderdata
```

```{r}
#LASSO Regression 

predictor_vars <- c("num_tests", "ethnicity", "race", "politicalid", "att_family", "att_carerr",
                     "age", "edu", "birthSex")
response_var <- as.vector(genderdata$score)

X <- as.matrix(genderdata[, predictor_vars])  # Predictor matrix
Y <- response_var  # Response variable

# Perform Lasso regression
lasso_model <- glmnet(X, Y, alpha = 1)  # alpha = 1 for Lasso regression

# Plot the cross-validated mean squared error (CV MSE) vs lambda
plot(lasso_model)

# Select lambda with minimum CV MSE
best_lambda <- cv.glmnet(X, Y, alpha = 1)$lambda.min

# Refit the model with the selected lambda
lasso_model_best <- glmnet(X, Y, alpha = 1, lambda = best_lambda)

# Make predictions
predictions <- predict(lasso_model_best, newx = X)

# Calculate MSE
mse <- mean((predictions - Y)^2)

# Print MSE
print(paste("Mean Squared Error (MSE):", mse))

# Print the coefficients
print(coef(lasso_model_best))
```

```{r}
#LASSO Regression 2
#predictor_vars <- c('num_tests', 'ethnicity', 'race', 'politicalid', 'skintone_preference', 'warmth_dark',
                #'warmth_light', 'age', 'edu', 'birthSex')

X <- as.matrix(genderdata[, predictor_vars])  # Predictor matrix
Y <- genderdata$score  # Response variable

# Create a grid of lambda values for cross-validation
lambda_grid <- 10^seq(10, -2, length = 100)

# Perform cross-validated Lasso regression
lasso_model_cv <- cv.glmnet(X, Y, alpha = 1, lambda = lambda_grid, nfolds = 10)

# Plot mean squared error (MSE) vs lambda
plot(lasso_model_cv)

# Select lambda with minimum MSE
best_lambda <- lasso_model_cv$lambda.min

# Refit the model with the selected lambda
lasso_model_best <- glmnet(X, Y, alpha = 1, lambda = best_lambda)

# Make predictions
predictions <- predict(lasso_model_best, newx = X)

# Calculate MSE
mse <- mean((predictions - Y)^2)

# Print MSE
print(paste('Mean Squared Error (MSE):', mse))

# Print the coefficients
print(coef(lasso_model_best))

print(best_lambda)
```

```{r}
#Best Subset Selection

# Generate all possible models
  all_models <- regsubsets(score ~ num_tests + ethnicity + politicalid
                           + age + edu + birthSex + race + att_family + att_carerr, 
                           data = genderdata, nvmax = 9)
  
  # Get the summary of all models
  summary_all <- summary(all_models)
  
  # Check if summary is empty
  if (length(summary_all$adjr2) == 0) {
    cat("No models were generated.")
    return(NULL)
  }
  
  # Find the best model based on adjusted R^2
  best_model <- which.max(summary_all$adjr2)
  
  # Get the details of the best model
  best_summary <- summary_all[best_model]
  
  # Get the formula of the best model
  formula_best <- names(which(summary_all$which[best_model, ]))
  
  # Print the results
  cat("Best model formula:", paste("y ~", paste(formula_best, collapse = " + ")), "\n")
```

```{r}
#Create categories

#create categories in score variable (no bias, moderate bias, strong bias)

# Define the breaks for creating three categories
breaks <- c(-Inf, -0.0001, 0.0001, 0.33, 0.66, Inf)

# Create a new categorical variable based on the breaks
genderdata$scorecat <- cut(genderdata$score, breaks = breaks, labels = c("Opposite", "None", "Low", "Medium", "High"))

# Print the summary of the new categorical variable
summary(genderdata$scorecat)
```

```{r}
#Multi ordinal logistic regression 1

# Fit ordinal logistic regression model
ord_model1 <- polr(scorecat ~ num_tests + ethnicity + politicalid
                           + age + edu + birthSex + race + att_family + att_carerr, 
                  data = genderdata, Hess = TRUE)

# Summarize the model
summary(ord_model1)
```

```{r}
#Multi ordinal logistic regression 2

# Fit ordinal logistic regression model
ord_model5 <- polr(scorecat ~ num_tests + politicalid
                           + age + birthSex + att_family + att_carerr, 
                  data = genderdata, Hess = TRUE)

# Summarize the model
summary(ord_model2)
```

Ord model 2 has the lowest AIC. 

```{r}
#table 
ctable <- coef(summary(ord_model2))

#calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2

## combined table
ctable <- cbind(ctable, "p value" = p)

#Confidence intervals 

ci <- confint(ord_model2)
ci
```

```{r}
#Odds Ratio and confidence intervals 

exp(cbind(OR = coef(ord_model2), ci))
```

```{r}
#Training and Test Data 

# Set seed for reproducibility (allows for the same random split when rerunning)
set.seed(123)

# Generate indices for train and test data
train_indices <- sample(1:nrow(genderdata), 0.8 * nrow(genderdata))  # 80% for training
test_indices <- setdiff(1:nrow(genderdata), train_indices)  # Remaining for testing

# Create training and test data frames
train_data <- genderdata[train_indices, ]
test_data <- genderdata[test_indices, ]
```

```{r}
#Ordinal regression predictions 

# Print summary of the model
#summary(ord_model)

# Predict classes
predicted_classes <- predict(ord_model2, newdata = test_data, type = "class")

# Create confusion matrix
conf_matrix <- table(test_data$scorecat, predicted_classes)

# Print confusion matrix
print(conf_matrix)
```






