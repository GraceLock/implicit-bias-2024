---
title: "401_sexualiaty"
author: "Grace Lock"
date: "2024-03-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(haven) #Reading in the data
library(dplyr)
library(tidyverse)
library(socsci) #Helps with data manipulation
library(glmnet) #Lasso Regression
library(nnet) #Multinomial Logistic Regression
library(rpart) #Regression Tree
library(leaps) #Best subset regression
library(MASS) #Ordinal logistic regression
```

### Sexuality data

```{r}
sexualitydata <- read_sav("/Users/gracelock/Downloads/Sexuality IAT.public.2023.sav")
```

```{r}
sexualitydata |> dplyr::select("session_id", "birthyear", "num_002", "birthSex", "ethnicityomb", "edu",
                     "raceomb_002", "D_biep.Straight_Good_all", "Tgayleswomen", "Tgaymen", "Tstraightmen",
                     "politicalid_7") |>
                na.omit("D_biep.Straight_Good_all") |>
                mutate(age = 2024-birthyear) |> 
                dplyr::select(-birthyear) |> 
                rename("num_tests" = "num_002",
                      "ethnicity" = "ethnicityomb",
                      "race" = "raceomb_002",
                      "politicalid" = "politicalid_7",
                      "score" = "D_biep.Straight_Good_all",
                      "warmth_gayleswomen" = "Tgayleswomen",
                      "warmth_gaymen" = "Tgaymen",
                      "warmth_straightmen" = "Tstraightmen") -> sexualitydata
```

```{r}
#LASSO Regression 

predictor_vars <- c("num_tests", "ethnicity", "race", "politicalid", "warmth_gayleswomen", "warmth_gaymen",
                     "warmth_straightmen", "age", "edu", "birthSex")
response_var <- as.vector(sexualitydata$score)

X <- as.matrix(sexualitydata[, predictor_vars])  # Predictor matrix
Y <- response_var  # Response variable

# Perform Lasso regression
lasso_model <- glmnet(X, Y, alpha = 1)  # alpha = 1 for Lasso regression

# Plot the cross-validated mean squared error (CV MSE) vs lambda
plot(lasso_model)

# Select lambda with minimum CV MSE
best_lambda <- cv.glmnet(X, Y, alpha = 1)$lambda.min

# Refit the model with the selected lambda
lasso_model_best <- glmnet(X, Y, alpha = 1, lambda = best_lambda)

# Make predictions
predictions <- predict(lasso_model_best, newx = X)

# Calculate MSE
mse <- mean((predictions - Y)^2)

# Print MSE
print(paste("Mean Squared Error (MSE):", mse))

# Print the coefficients
print(coef(lasso_model_best))
```

```{r}
#LASSO Regression 2
#predictor_vars <- c('num_tests', 'ethnicity', 'race', 'politicalid', 'skintone_preference', 'warmth_dark',
                #'warmth_light', 'age', 'edu', 'birthSex')

X <- as.matrix(sexualitydata[, predictor_vars])  # Predictor matrix
Y <- sexualitydata$score  # Response variable

# Create a grid of lambda values for cross-validation
lambda_grid <- 10^seq(10, -2, length = 100)

# Perform cross-validated Lasso regression
lasso_model_cv <- cv.glmnet(X, Y, alpha = 1, lambda = lambda_grid, nfolds = 10)

# Plot mean squared error (MSE) vs lambda
plot(lasso_model_cv)

# Select lambda with minimum MSE
best_lambda <- lasso_model_cv$lambda.min

# Refit the model with the selected lambda
lasso_model_best <- glmnet(X, Y, alpha = 1, lambda = best_lambda)

# Make predictions
predictions <- predict(lasso_model_best, newx = X)

# Calculate MSE
mse <- mean((predictions - Y)^2)

# Print MSE
print(paste('Mean Squared Error (MSE):', mse))

# Print the coefficients
print(coef(lasso_model_best))

print(best_lambda)
```

```{r}
#Best Subset Selection

# Generate all possible models
  all_models <- regsubsets(score ~ num_tests + ethnicity + politicalid + age + edu + 
                           birthSex + race + warmth_gayleswomen + warmth_gaymen + warmth_straightmen, 
                           data = sexualitydata, nvmax = 10)
  
  # Get the summary of all models
  summary_all <- summary(all_models)
  
  # Check if summary is empty
  if (length(summary_all$adjr2) == 0) {
    cat("No models were generated.")
    return(NULL)
  }
  
  # Find the best model based on adjusted R^2
  best_model <- which.max(summary_all$adjr2)
  
  # Get the details of the best model
  best_summary <- summary_all[best_model]
  
  # Get the formula of the best model
  formula_best <- names(which(summary_all$which[best_model, ]))
  
  # Print the results
  cat("Best model formula:", paste("y ~", paste(formula_best, collapse = " + ")), "\n")
```


```{r}
#Create categories

#create categories in score variable (no bias, moderate bias, strong bias)

# Define the breaks for creating three categories
breaks <- c(-Inf, -0.0001, 0.0001, 0.33, 0.66, Inf)

# Create a new categorical variable based on the breaks
sexualitydata$scorecat <- cut(sexualitydata$score, breaks = breaks, labels = c("Opposite", "None", "Low", "Medium", "High"))

# Print the summary of the new categorical variable
summary(sexualitydata$scorecat)
```

```{r}
#Multi ordinal logistic regression 1 

# Fit ordinal logistic regression model
ord_model1 <- polr(scorecat ~ num_tests + politicalid + age + edu + ethnicity +
                           birthSex + race + warmth_gayleswomen + warmth_gaymen + warmth_straightmen, 
                  data = sexualitydata, Hess = TRUE)

# Summarize the model
summary(ord_model1)
```

```{r}
#Multi ordinal logistic regression 2

# Fit ordinal logistic regression model
ord_model5 <- polr(scorecat ~ num_tests + politicalid + age + 
                           birthSex + race + warmth_gayleswomen + warmth_gaymen + warmth_straightmen, 
                  data = sexualitydata, Hess = TRUE)

# Summarize the model
summary(ord_model2)
```

AICs:
Ord model 2 has the lowest AIC value.  

```{r}
#table 
ctable <- coef(summary(ord_model2))

#calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2

## combined table
ctable <- cbind(ctable, "p value" = p)

#Confidence intervals 
ci <- confint(ord_model2)
ci
```

```{r}
#Odds Ratio and confidence intervals 
exp(cbind(OR = coef(ord_model2), ci))
```

```{r}
#Training and Test Data 

# Set seed for reproducibility (allows for the same random split when rerunning)
set.seed(123)

# Generate indices for train and test data
train_indices <- sample(1:nrow(sexualitydata), 0.8 * nrow(sexualitydata))  # 80% for training
test_indices <- setdiff(1:nrow(sexualitydata), train_indices)  # Remaining for testing

# Create training and test data frames
train_data <- sexualitydata[train_indices, ]
test_data <- sexualitydata[test_indices, ]
```

```{r}
#Ordinal regression predictions 

# Predict classes
predicted_classes <- predict(ord_model2, newdata = test_data, type = "class")

# Create confusion matrix
conf_matrix <- table(test_data$scorecat, predicted_classes)

# Print confusion matrix
print(conf_matrix)
```
