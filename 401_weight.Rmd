---
title: "401_Weight"
author: "Grace Lock"
date: "2024-03-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(haven) #Reading in the data
library(dplyr)
library(tidyverse)
library(socsci) #Helps with data manipulation
library(glmnet) #Lasso Regression
library(nnet) #Multinomial Logistic Regression
library(rpart) #Regression Tree
library(leaps) #Best subset regression
library(MASS) #Ordinal logistic regression
```

### Weight data 

```{r}
weightdata <- read_sav("/Users/gracelock/Downloads/Weight IAT.public.2023.sav")
```

```{r}
weightdata |> dplyr::select("session_id", "birthyear", "num_002", "birthSex", "ethnicityomb", "edu",
                            "politicalid_7", "raceomb_002", "D_biep.Thin_Good_all", "att7", "tthin", 
                            "tfat", "comptomost_001") |>
              na.omit("D_biep.Thin_Good_all") |>
              mutate(age = 2024-birthyear) |> 
              dplyr::select(-birthyear) |> 
              rename("num_tests" = "num_002",
                      "ethnicity" = "ethnicityomb",
                      "race" = "raceomb_002",
                      "score" = "D_biep.Thin_Good_all",
                      "body_preference" = "att7",
                      "warmth_thin" = "tthin",
                      "warmth_fat" = "tfat",
                      "comptomost" = "comptomost_001",
                      "politicalid" = "politicalid_7") -> weightdata

#comptomost: 1 "Much thinner" 2 "Moderately thinner" 3 "Slightly thinner" 4 "About the same" 5 "Slightly heavier" 6 "Moderately heavier" 7 "Much heavier"
```

```{r}
#LASSO Regression 

predictor_vars <- c("num_tests", "ethnicity", "race", "politicalid", "warmth_thin", "warmth_fat",
                     "comptomost", "age", "edu", "birthSex")
response_var <- as.vector(weightdata$score)

X <- as.matrix(weightdata[, predictor_vars])  # Predictor matrix
Y <- response_var  # Response variable

# Perform Lasso regression
lasso_model <- glmnet(X, Y, alpha = 1)  # alpha = 1 for Lasso regression

# Plot the cross-validated mean squared error (CV MSE) vs lambda
plot(lasso_model)

# Select lambda with minimum CV MSE
best_lambda <- cv.glmnet(X, Y, alpha = 1)$lambda.min

# Refit the model with the selected lambda
lasso_model_best <- glmnet(X, Y, alpha = 1, lambda = best_lambda)

# Make predictions
predictions <- predict(lasso_model_best, newx = X)

# Calculate MSE
mse <- mean((predictions - Y)^2)

# Print MSE
print(paste("Mean Squared Error (MSE):", mse))

# Print the coefficients
print(coef(lasso_model_best))
```

```{r}
#LASSO Regression 2
#predictor_vars <- c('num_tests', 'ethnicity', 'race', 'politicalid', 'skintone_preference', 'warmth_dark',
                #'warmth_light', 'age', 'edu', 'birthSex')

X <- as.matrix(weightdata[, predictor_vars])  # Predictor matrix
Y <- weightdata$score  # Response variable

# Create a grid of lambda values for cross-validation
lambda_grid <- 10^seq(10, -2, length = 100)

# Perform cross-validated Lasso regression
lasso_model_cv <- cv.glmnet(X, Y, alpha = 1, lambda = lambda_grid, nfolds = 10)

# Plot mean squared error (MSE) vs lambda
plot(lasso_model_cv)

# Select lambda with minimum MSE
best_lambda <- lasso_model_cv$lambda.min

# Refit the model with the selected lambda
lasso_model_best <- glmnet(X, Y, alpha = 1, lambda = best_lambda)

# Make predictions
predictions <- predict(lasso_model_best, newx = X)

# Calculate MSE
mse <- mean((predictions - Y)^2)

# Print MSE
print(paste('Mean Squared Error (MSE):', mse))

# Print the coefficients
print(coef(lasso_model_best))

print(best_lambda)
```

```{r}
#Best subset selection 1

# Perform best subset selection
subset_model <- regsubsets(score ~ num_tests + ethnicity + politicalid + age + edu + 
                           birthSex + race + warmth_thin + warmth_fat + comptomost, 
                           data = weightdata, nvmax = 8)

# Get the best model based on adjusted R-squared
best_model <- which.max(summary(subset_model)$adjr2)

# Summary of the best model
summary(subset_model, id = best_model)
```

```{r}
#Best subset selection 2

# Perform best subset selection
subset_model <- regsubsets(score ~ num_tests + ethnicity + politicalid + age + edu + 
                           birthSex + race + warmth_thin + warmth_fat + comptomost, 
                           data = weightdata, nvmax = 6)

# Get the best model based on adjusted R-squared
best_model <- which.max(summary(subset_model)$adjr2)

# Summary of the best model
summary(subset_model, id = best_model)
```

```{r}
#Best subset selection 3

# Perform best subset selection
subset_model <- regsubsets(score ~ num_tests + ethnicity + politicalid + age + edu + 
                           birthSex + race + warmth_thin + warmth_fat + comptomost, 
                           data = weightdata, nvmax = 4)

# Get the best model based on adjusted R-squared
best_model <- which.max(summary(subset_model)$adjr2)

# Summary of the best model
summary(subset_model, id = best_model)
```

```{r}
#Best subset selection 4

# Perform best subset selection
subset_model <- regsubsets(score ~ num_tests + ethnicity + politicalid + age + edu + 
                           birthSex + race + warmth_thin + warmth_fat + comptomost, 
                           data = weightdata, nvmax = 3)

# Get the best model based on adjusted R-squared
best_model <- which.max(summary(subset_model)$adjr2)

# Summary of the best model
summary(subset_model, id = best_model)
```

```{r}
#Create categories

#create categories in score variable (no bias, moderate bias, strong bias)

# Define the breaks for creating three categories
breaks <- c(-Inf, -0.0001, 0.0001, 0.33, 0.66, Inf)

# Create a new categorical variable based on the breaks
weightdata$scorecat <- cut(weightdata$score, breaks = breaks, labels = c("Opposite", "None", "Low", "Medium", "High"))

# Print the summary of the new categorical variable
summary(weightdata$scorecat)
```

```{r}
#Multi ordinal logistic regression 

# Fit ordinal logistic regression model
ord_model <- polr(scorecat ~ num_tests + ethnicity + politicalid + age + edu + 
                           birthSex + race + warmth_thin + warmth_fat + comptomost, 
                  data = weightdata, Hess = TRUE)

# Summarize the model
summary(ord_model)
```

```{r}
#table 
ctable <- coef(summary(ord_model))
```

```{r}
#calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2

## combined table
(ctable <- cbind(ctable, "p value" = p))
```

```{r}
#Confidence intervals 
ci <- confint(ord_model)
ci
```

```{r}
#Odds Ratio and confidence intervals 
exp(cbind(OR = coef(ord_model), ci))
```

```{r}
#Training and Test Data 

# Set seed for reproducibility (allows for the same random split when rerunning)
set.seed(123)

# Generate indices for train and test data
train_indices <- sample(1:nrow(weightdata), 0.8 * nrow(weightdata))  # 80% for training
test_indices <- setdiff(1:nrow(weightdata), train_indices)  # Remaining for testing

# Create training and test data frames
train_data <- weightdata[train_indices, ]
test_data <- weightdata[test_indices, ]
```

```{r}
#Ordinal regression predictions 

# Predict classes
predicted_classes <- predict(ord_model, newdata = test_data, type = "class")

# Create confusion matrix
conf_matrix <- table(test_data$scorecat, predicted_classes)

# Print confusion matrix
print(conf_matrix)
```







