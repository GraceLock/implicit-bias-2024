---
title: "DA401 Project"
author: "Grace Lock"
date: "2024-01-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(haven) #Reading in the data
library(dplyr)
library(tidyverse)
library(socsci) #Helps with data manipulation
library(glmnet) #Lasso Regression
library(reshape2) #Lasso Regression visual 
library(nnet) #Multinomial Logistic Regression
library(rpart) #Regression Tree
library(leaps) #Best subset regression
library(MASS) #Multiordinal logistic regression - messes with dplyr select function
```


### Skin tone data 

```{r}
skintonedata <- read_sav("/Users/gracelock/Downloads/Skin IAT.public.2023 2.sav")

skintonedata |>  dplyr::select("session_id", "birthyear", "birthSex", "politicalid_7",
                                 "num_002", "ethnicityomb", "raceomb_002", "edu", "D_biep.LightSkin_Good_all", 
                                 "att7", "Tdark", "Tlight") |>
                 na.omit("D_biep.LightSkin_Good_all") |>
                 rename("num_tests" = "num_002",
                        "ethnicity" = "ethnicityomb",
                        "race" = "raceomb_002",
                        "politicalid" = "politicalid_7",
                        "skintone_preference" = "att7",
                        "warmth_dark" = "Tdark",
                        "warmth_light" = "Tlight",
                        "score" = "D_biep.LightSkin_Good_all") |>
                 mutate(age = 2024 - birthyear) |>
                 dplyr::select(-birthyear) -> skintonedata

#birthsex: 1 = male, 2 = female

#warmth: 0 "Extremely cold" 1 "Very cold" 2 "Moderately cold" 3 "Somewhat cold" 4 "Slightly cold" 5 "Neither warm nor cold" 6 "Slightly warm" 7 "Somewhat warm" 8 "Moderately warm" 9 "Very warm" 10 "Extremely warm" 

#skintone_preference: 1 "I strongly prefer Dark Skinned People to Light Skinned People." 2 "I moderately prefer Dark Skinned People to Light Skinned People." 3 "I slightly prefer Dark Skinned People to Light Skinned People." 4 "I like Light Skinned People and Dark Skinned People equally." 5 "I slightly prefer Light Skinned People to Dark Skinned People." 6 "I moderately prefer Light Skinned People to Dark Skinned People." 7 "I strongly prefer Light Skinned People to Dark Skinned People." 

#race: 1 = American Indian/Alaska Native, 2	= East Asian, 3 = South Asian, 4 = Native Hawaiian or other Pacific #Islander, 5 = Black or African American, 6	= White, 7 = Other or Unknown, 8 = Multiracial

#ethnicity:1 "Hispanic or Latino" 2 "Not Hispanic or Latino" 3 "Unknown"

#politicalid: 1 "strongly conservative" 2 "moderately conservative" 3 "slightly conservative" 4 "neutral" 5 "slightly liberal" 6 "moderately liberal" 7 "strongly liberal"
```


```{r}
#LASSO Regression 

predictor_vars <- c("num_tests", "ethnicity", "race", "politicalid", "skintone_preference", "warmth_dark",
                "warmth_light", "age", "edu", "birthSex")
response_var <- as.vector(skintonedata$score)

X <- as.matrix(skintonedata[, predictor_vars])  # Predictor matrix
Y <- response_var  # Response variable

# Perform Lasso regression
lasso_model <- glmnet(X, Y, alpha = 1)  # alpha = 1 for Lasso regression

# Plot the cross-validated mean squared error (CV MSE) vs lambda
plot(lasso_model)

# Select lambda with minimum CV MSE
best_lambda <- cv.glmnet(X, Y, alpha = 1)$lambda.min

# Refit the model with the selected lambda
lasso_model_best <- glmnet(X, Y, alpha = 1, lambda = best_lambda)

# Make predictions
predictions <- predict(lasso_model_best, newx = X)

# Calculate MSE
mse <- mean((predictions - Y)^2)

# Print MSE
print(paste("Mean Squared Error (MSE):", mse))

# Print the coefficients
print(coef(lasso_model_best))
```

Non-zero coefficients: Predictors with non-zero coefficients in the printed output are selected by the Lasso regression model. These predictors are deemed to have a significant influence on the response variable.

Zero coefficients: Predictors with coefficients set to zero in the printed output are effectively excluded from the model. These predictors are considered to have little or no impact on the response variable according to the Lasso regularization.

Coefficient values: The magnitude of the coefficients indicates the strength of the relationship between each predictor and the response variable. Larger coefficient values suggest stronger relationships, whereas smaller values suggest weaker relationships.

Intercept term: Lasso regression also estimates an intercept term, which represents the expected value of the response variable when all predictor variables are zero.

```{r}
#LASSO Regression 2
predictor_vars <- c('num_tests', 'ethnicity', 'race', 'politicalid', 'skintone_preference', 'warmth_dark',
                'warmth_light', 'age', 'edu', 'birthSex')

X <- as.matrix(skintonedata[, predictor_vars])  # Predictor matrix
Y <- skintonedata$score  # Response variable

# Create a grid of lambda values for cross-validation
lambda_grid <- 10^seq(10, -2, length = 100)

# Perform cross-validated Lasso regression
lasso_model_cv <- cv.glmnet(X, Y, alpha = 1, lambda = lambda_grid, nfolds = 10)

# Plot mean squared error (MSE) vs lambda
plot(lasso_model_cv)

# Select lambda with minimum MSE
best_lambda <- lasso_model_cv$lambda.min

# Refit the model with the selected lambda
lasso_model_best <- glmnet(X, Y, alpha = 1, lambda = best_lambda)

# Make predictions
predictions <- predict(lasso_model_best, newx = X)

# Calculate MSE
mse <- mean((predictions - Y)^2)

# Print MSE
print(paste('Mean Squared Error (MSE):', mse))

# Print the coefficients
print(coef(lasso_model_best))

print(best_lambda)

```


```{r}
#Dot Plot 
df <- data.frame(
  Row = c("Sex", "Education", "Political Identity", "Age", "Race", "Ethnicity", "Number of Tests", 
                  "Warmth 1", "Warmth 2", "Warmth 3"),
  Skintone = c(1, 1, 1, 1, 0, 1, 1, 1, 1, 0),
  Weight = c(1, 0, 1, 1, 0, 0, 1, 1, 1, 1),
  Gender = c(1, 1, 1, 1, 1, 0, 1, 1, 1, 0),
  Sexuality = c(1, 0, 1, 1, 1, 0, 1, 1, 1, 1)
)

data_long <- melt(df, id.vars = "Row", variable.name = "Category", value.name = "Value")
data_long$Row <- factor(data_long$Row, levels = c("Political Identity", "Number of Tests", "Age", "Warmth 3",
                                                  "Warmth 2", "Warmth 1", "Sex", "Race", "Ethnicity", "Education"))

data_long |> 
  ggplot() + 
  aes(x = Category, y = Row, color = as.factor(Value)) + 
  geom_point(size = 5) +
  scale_color_manual(values = c("red", "green"), labels = c("No", "Yes")) +
  labs(title = "Variable selection for the best model",
       x = "Bias Type",
       y = "Predictors",
       color = "Variable was selected:",
       subtitle = "'best' model means the model with the lowest AIC value",
       caption = "Warmth 1, 3, and 3 represent how warm or cold a participant feels towards the groups\nof people in that bias test. See __ for more specifics on the warmth questions for each test.") +
  theme_minimal() +
  theme(legend.position = "bottom") 
```

```{r}
#Multiple linear regression 

predictor_vars <- c("num_tests", "ethnicity", "politicalid", "skintone_preference",
                    "warmth_light", "age", "edu", "birthSex")

# Set seed for reproducibility (allows for the same random split when rerunning)
set.seed(123)

# Generate indices for train and test data
train_indices <- sample(1:nrow(skintonedata), 0.8 * nrow(skintonedata))  # 80% for training
test_indices <- setdiff(1:nrow(skintonedata), train_indices)  # Remaining for testing

# Create training and test data frames
train_data <- skintonedata[train_indices, ]
test_data <- skintonedata[test_indices, ]

train_data <- train_data[, c(predictor_vars, "score")]
test_data <- test_data[, c(predictor_vars, "score")]

#Model
model <- lm(score ~ num_tests + ethnicity + politicalid+skintone_preference+
                    warmth_light+age+edu+birthSex, data = train_data)

# Summary of the model
summary(model)

# Predictions
predictions <- predict(model, test_data)

# Visualize actual vs predicted values
plot(test_data$score, predictions, xlab = "Actual", ylab = "Predicted", main = "Actual vs Predicted")
abline(0, 1, col = "red")  # add a 45-degree line for comparison
```

```{r}
#Best Subset Selection 1

# Perform best subset selection
subset_model <- regsubsets(score ~ num_tests + ethnicity + politicalid + skintone_preference +
                    warmth_light + age + edu + birthSex + race + warmth_dark, data = skintonedata, nvmax = 8)

# Get the best model based on adjusted R-squared
best_model <- which.max(summary(subset_model)$adjr2)

# Summary of the best model
summary(subset_model, id = best_model)
```

```{r}
#Best Subset Selection 2

# Perform best subset selection
subset_model <- regsubsets(score ~ num_tests + ethnicity + politicalid + skintone_preference +
                    warmth_light + age + edu + birthSex + race + warmth_dark, data = skintonedata, nvmax = 6)

# Get the best model based on adjusted R-squared
best_model <- which.max(summary(subset_model)$adjr2)

# Summary of the best model
summary(subset_model, id = best_model)
```

```{r}
#Best Subset Selection 3

# Perform best subset selection
subset_model <- regsubsets(score ~ num_tests + ethnicity + politicalid + skintone_preference +
                    warmth_light + age + edu + birthSex + race + warmth_dark, data = skintonedata, nvmax = 4)

# Get the best model based on adjusted R-squared
best_model <- which.max(summary(subset_model)$adjr2)

# Summary of the best model
summary(subset_model, id = best_model)
```

```{r}
#Best Subset Selection 4

# Perform best subset selection
subset_model <- regsubsets(score ~ num_tests + ethnicity + politicalid + skintone_preference +
                    warmth_light + age + edu + birthSex + race + warmth_dark, data = skintonedata, nvmax = 3)

# Get the best model based on adjusted R-squared
best_model <- which.max(summary(subset_model)$adjr2)

# Summary of the best model
summary(subset_model, id = best_model)
```

```{r}
#Best Subset Selection Visual 

selections_df <- data.frame(
  nvmax = c(8, 6, 4, 3),
  num_tests = c(1, 1, 1, 1),
  age = c(1, 1, 1, 1),
  skintone_preference = c(1, 1, 1, 1),
  politicalid = c(1, 1, 1, 0),
  ethnicity = c(1, 1, 0, 0),
  edu = c(1, 1, 0, 0),
  warmth_light = c(1, 0, 0, 0),
  birthSex = c(1, 0, 0, 0),
  race = c(0, 0, 0, 0),
  warmth_dark = c(0, 0, 0, 0)
)

data_longer <- melt(selections_df, id.vars = "nvmax", variable.name = "Category", value.name = "Value")
#data_long$Row <- factor(data_long$Row, levels = c("Political Identity", "Number of Tests", "Age", "Warmth 3",
#                                                 "Warmth 2", "Warmth 1", "Sex", "Race", "Ethnicity", "Education"))

data_longer |> 
  ggplot() + 
  aes(x = Category, y = nvmax, color = as.factor(Value)) + 
  geom_point(size = 5) +
  scale_color_manual(values = c("red", "green"), labels = c("No", "Yes")) +
  labs(title = "Best Subset Selection: Skintone Data",
       x = "Predictors",
       y = "Number of predictors to select",
       color = "Variable was selected:") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  theme(
    axis.text.x = element_text(angle = 25, hjust = 1)
  )
```

```{r}
#Multiple Linear Regressions

predictor_vars <- c("num_tests", "ethnicity", "politicalid", "skintone_preference",
                    "warmth_light", "age", "edu", "birthSex")

# Set seed for reproducibility (allows for the same random split when rerunning)
set.seed(123)

# Generate indices for train and test data
train_indices <- sample(1:nrow(skintonedata), 0.8 * nrow(skintonedata))  # 80% for training
test_indices <- setdiff(1:nrow(skintonedata), train_indices)  # Remaining for testing

# Create training and test data frames
train_data <- skintonedata[train_indices, ]
test_data <- skintonedata[test_indices, ]

train_data <- train_data[, c(predictor_vars, "score")]
test_data <- test_data[, c(predictor_vars, "score")]

#Models
model8 <- lm(score ~ num_tests + ethnicity + politicalid+skintone_preference+
                    warmth_light+age+edu+birthSex, data = train_data)
model6 <- lm(score ~ num_tests + ethnicity + politicalid+skintone_preference+age+edu, data = train_data)
model4 <- lm(score ~ num_tests + politicalid+skintone_preference+age, data = train_data)
model3 <- lm(score ~ num_tests +skintone_preference+age, data = train_data)

# Summary of the model
summary(model8) #0.07529
summary(model6) #0.0751
summary(model4) #0.07367
summary(model3) #0.06924

# Predictions
predictions <- predict(model3, test_data)

# Visualize actual vs predicted values
plot(test_data$score, predictions, xlab = "Actual", ylab = "Predicted", main = "Actual vs Predicted")
abline(0, 1, col = "red")  # add a 45-degree line for comparison
```


```{r}
#Create categories

#create categories in score variable (no bias, moderate bias, strong bias)

# Define the breaks for creating three categories
breaks <- c(-Inf, -0.0001, 0.0001, 0.33, 0.66, Inf)

# Create a new categorical variable based on the breaks
skintonedata$scorecat <- cut(skintonedata$score, breaks = breaks, labels = c("Opposite", "None", "Low", "Medium", "High"))

# Print the summary of the new categorical variable
summary(skintonedata$scorecat)
```

```{r}
#Multi ordinal logistic regression 1

# Fit ordinal logistic regression model
ord_model1 <- polr(scorecat ~ num_tests + ethnicity + politicalid + skintone_preference +
                    warmth_light + age + edu + birthSex, data = skintonedata, Hess = TRUE)

# Summarize the model
summary(ord_model1)
```

```{r}
#Multi ordinal logistic regression 2

# Fit ordinal logistic regression model
ord_model2 <- polr(scorecat ~ num_tests + ethnicity + politicalid + skintone_preference +
                     age + edu, data = skintonedata, Hess = TRUE)

# Summarize the model
summary(ord_model2)
```

```{r}
#Multi ordinal logistic regression 3

# Fit ordinal logistic regression model
ord_model3 <- polr(scorecat ~ num_tests + politicalid + skintone_preference +
                     age, data = skintonedata, Hess = TRUE)

# Summarize the model
summary(ord_model3)
```

```{r}
#Multi ordinal logistic regression 4

# Fit ordinal logistic regression model
ord_model4 <- polr(scorecat ~ num_tests + skintone_preference +age, 
                   data = skintonedata, Hess = TRUE)

# Summarize the model
summary(ord_model4)
```

```{r}
#Multi ordinal logistic regression 5

# Fit ordinal logistic regression model
ord_model5 <- polr(scorecat ~ num_tests + ethnicity + politicalid + skintone_preference +
                     age + edu, 
                   data = skintonedata, Hess = TRUE)

# Summarize the model
summary(ord_model5)
```

AICs: 63588.17, 63594.22, 63632.46, 63738.49, 63594.22 (lasso)
Ord model 1 has the lowest AIC. 
Ord model 4 has the highest AIC. 

```{r}
#table 
ctable <- coef(summary(ord_model1))

#calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2

## combined table
ctable <- cbind(ctable, "p value" = p)
```

```{r}
#Confidence intervals 
ci <- confint(ord_model1)
ci
```

The 95% confidence intervals do not cross 0 so therefor they are significant - though they are very close to 0. 

```{r}
#Odds Ratio and confidence intervals 
exp(cbind(OR = coef(ord_model1), ci))
```

For every one unit increase in number of tests taken, the odds of being more bias is multiplied .85 times, holding constant all other variables. 
For every one unit increase in ethnicity, the odds of being more bias is multiplied 1.12 times or increases 12%, holding constant all other variables. 
The odds ratio is greatest for skintone_preference showing that this has the greatest impact which is in line with other models. 

```{r}
#Training and Test Data 

# Set seed for reproducibility (allows for the same random split when rerunning)
set.seed(123)

# Generate indices for train and test data
train_indices <- sample(1:nrow(skintonedata), 0.8 * nrow(skintonedata))  # 80% for training
test_indices <- setdiff(1:nrow(skintonedata), train_indices)  # Remaining for testing

# Create training and test data frames
train_data <- skintonedata[train_indices, ]
test_data <- skintonedata[test_indices, ]
```

```{r}
#Ordinal regression predictions 

# Predict classes
predicted_classes <- predict(ord_model1, newdata = test_data, type = "class")

# Create confusion matrix
conf_matrix <- table(test_data$scorecat, predicted_classes)

# Print confusion matrix
print(conf_matrix)
```


```{r}
#Logistic regression (og)

predictor_vars0 <- c("num_tests", "ethnicity", "politicalid", "skintone_preference",
                    "warmth_light", "age", "edu", "birthSex")

train_data0 <- train_data[, c(predictor_vars0, "scorecat")]
test_data0 <- test_data[, c(predictor_vars0, "scorecat")]

# Fit multinomial logistic regression model
multinom_model0 <- multinom(scorecat ~ ., data = train_data0)

# Print summary of the model
summary(multinom_model0)
```

```{r}
#Logistic Regression best subset regression 1

predictor_vars1 <- c("num_tests", "ethnicity", "politicalid", "skintone_preference",
                    "age", "edu")

train_data1 <- train_data[, c(predictor_vars1, "scorecat")]
test_data1 <- test_data[, c(predictor_vars1, "scorecat")]

# Fit multinomial logistic regression model
multinom_model1 <- multinom(scorecat ~ ., data = train_data1)

# Print summary of the model
summary(multinom_model1)
```

```{r}
#Logistic Regression best subset regression 2

predictor_vars2 <- c("num_tests", "politicalid", "skintone_preference", "age")

train_data2 <- train_data[, c(predictor_vars2, "scorecat")]
test_data2 <- test_data[, c(predictor_vars2, "scorecat")]

# Fit multinomial logistic regression model
multinom_model2 <- multinom(scorecat ~ ., data = train_data2)

# Print summary of the model
summary(multinom_model2)
```

```{r}
#Logistic Regression best subset regression 3

predictor_vars3 <- c("num_tests", "skintone_preference", "age")

train_data3 <- train_data[, c(predictor_vars3, "scorecat")]
test_data3 <- test_data[, c(predictor_vars3, "scorecat")]

# Fit multinomial logistic regression model
multinom_model3 <- multinom(scorecat ~ ., data = train_data3)

# Print summary of the model
summary(multinom_model3)
```

```{r}
#Logistic Regression best subset regression 4

predictor_vars4 <- c("num_tests", "ethnicity", "politicalid", "skintone_preference",
                    "warmth_light", "age", "edu", "birthSex")

train_data4 <- train_data[, c(predictor_vars4, "scorecat")]
test_data4 <- test_data[, c(predictor_vars4, "scorecat")]

# Fit multinomial logistic regression model
multinom_model4 <- multinom(scorecat ~ ., data = train_data4)

# Print summary of the model
summary(multinom_model4)
```


```{r}
#Logistic Regression Visual 

# Predict classes
predicted_classes <- predict(multinom_model, newdata = test_data, type = "class")

# Create confusion matrix
conf_matrix <- table(test_data$scorecat, predicted_classes)

# Print confusion matrix
print(conf_matrix)
```

```{r}
# Predict probabilities for each class
predicted_probs <- predict(multinom_model, newdata = skintonedata, type = "probs")

# Extract the predicted probabilities for the true class
true_class_probs <- predicted_probs[cbind(1:nrow(skintonedata), as.numeric(skintonedata$scorecat))]

# Calculate log loss for each observation
log_loss <- -log(true_class_probs)

# Plot the distribution of log loss values
hist(log_loss, main = "Distribution of Log Loss", 
     xlab = "Log Loss", 
     ylab = "Frequency", 
     col = "skyblue", 
     border = "white")
```

This visualization provides insights into the distribution of log loss values, which is a measure of the accuracy of the predicted probabilities. Lower log loss values indicate better calibration of predicted probabilities to the true outcomes.

The log loss is defined as the negative natural logarithm of the predicted probability assigned to the true class. This value is commonly used as a measure of the accuracy of predicted probabilities in classification tasks.

```{r}
#Regression Tree 

predictor_vars <- c("num_tests", "ethnicity", "race", "politicalid", "skintone_preference", "warmth_dark",
                "warmth_light")
response_var <- skintonedata$score

# Fit regression tree model
#tree_model <- rpart(response_var ~ ., data = skintonedata[, c(predictor_vars, "scorecat")], method = "anova")
tree_model <- rpart(response_var ~ ., data = skintonedata[, c(predictor_vars, "scorecat")], method = "class")

# Print the tree
print(tree_model)

# Plot the tree
plot(tree_model)
text(tree_model)
```

### Citations

```{r}
rpart_cit <- citation("rpart")
glmnet_cit <- citation("glmnet")
```


